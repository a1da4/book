{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chap3_clustering.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Db7BW0cTft-A","colab_type":"text"},"source":["# Generate feed vector"]},{"cell_type":"code","metadata":{"id":"GgMrk5RrZ4_O","colab_type":"code","outputId":"aec783a2-34fa-43c6-ac4c-c2e4be5513c7","executionInfo":{"status":"ok","timestamp":1575091075893,"user_tz":-540,"elapsed":12682,"user":{"displayName":"Taichi Aida","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcKjJGJr5u3skF7CZzcu0m1n_npdAFxPcT51W3=s64","userId":"09772046621551990942"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["!pip install feedparser"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting feedparser\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n","\r\u001b[K     |█▊                              | 10kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 133kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 143kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 153kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 163kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 174kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 184kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 2.9MB/s \n","\u001b[?25hBuilding wheels for collected packages: feedparser\n","  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=445d4e85bbc6cddfc8da16da755601e911d691135479ee81f455bf7bbe9b2cd0\n","  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n","Successfully built feedparser\n","Installing collected packages: feedparser\n","Successfully installed feedparser-5.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9-waxNl4Z9KV","colab_type":"code","colab":{}},"source":["import feedparser\n","import re"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GUekSVGKaPeI","colab_type":"code","colab":{}},"source":["# Calculate word frequency in each blog\n","def get_word_counts(url):\n","  d = feedparser.parse(url)\n","\n","  wc = {}\n","  \n","  for e in d.entries:\n","    if 'summary' in e:\n","      summary = e.summary\n","    else:\n","      summary = e.description\n","    #print('summary: %s' % summary)\n","\n","    words = get_words(e.title+' '+summary)\n","    for word in words:\n","      wc.setdefault(word, 0)\n","      wc[word]+=1\n","  \n","  return d.feed.title, wc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9vgdF02cbaC","colab_type":"code","colab":{}},"source":["# html-like title and summary -> words\n","def get_words(html):\n","  txt = re.compile(r'<[^>]+>').sub('',html)\n","  words = re.compile(r'[^A-Z^a-z]+').split(txt)\n","  \n","  #print('get_words, txt: %s' % txt)\n","  #print('get_words, words: %s' % words)\n","\n","  return [word.lower() for word in words if word != '']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PWFngM0wbB6k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":765},"outputId":"fd20af80-faf9-40f1-cd85-9ae695071614","executionInfo":{"status":"ok","timestamp":1575093466548,"user_tz":-540,"elapsed":1091010,"user":{"displayName":"Taichi Aida","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcKjJGJr5u3skF7CZzcu0m1n_npdAFxPcT51W3=s64","userId":"09772046621551990942"}}},"source":["# ap_count: number of blog each word appeared\n","ap_count = {}\n","word_counts = {}\n","\n","failed_count = 0\n","\n","with open('feedlist.txt') as f:\n","  feed_list = [re.sub(r'\\n', '', line) for line in f.readlines()]\n","\n","for feed_url in feed_list:\n","  try:\n","    title, wc = get_word_counts(feed_url)\n","    word_counts[title] = wc\n","    for word, count in wc.items():\n","      ap_count.setdefault(word, 0)\n","      if count > 1:\n","        ap_count[word] += 1\n","  except:\n","    print('Failed to parse feed %s' % feed_url)\n","    failed_count += 1\n","\n","print('Conpleted. Failed to parse %.2f' % (failed_count/len(feed_list)))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Failed to parse feed http://battellemedia.com/index.xml\n","Failed to parse feed http://feeds.searchenginewatch.com/sewblog\n","Failed to parse feed http://blog.topix.net/index.rdf\n","Failed to parse feed http://blogs.abcnews.com/theblotter/index.rdf\n","Failed to parse feed http://feeds.feedburner.com/ConsumingExperienceFull\n","Failed to parse feed http://flagrantdisregard.com/index.php/feed/\n","Failed to parse feed http://featured.gigaom.com/feed/\n","Failed to parse feed http://gofugyourself.typepad.com/go_fug_yourself/index.rdf\n","Failed to parse feed http://feeds.feedburner.com/instapundit/main\n","Failed to parse feed http://jeremy.zawodny.com/blog/rss2.xml\n","Failed to parse feed http://michellemalkin.com/index.rdf\n","Failed to parse feed http://beta.blogger.com/feeds/27154654/posts/full?alt=rss\n","Failed to parse feed http://powerlineblog.com/index.rdf\n","Failed to parse feed http://feeds.feedburner.com/Publishing20\n","Failed to parse feed http://scobleizer.wordpress.com/feed/\n","Failed to parse feed http://www.456bereastreet.com/feed.xml\n","Failed to parse feed http://www.bloglines.com/rss/about/news\n","Failed to parse feed http://www.coolhunting.com/index.rdf\n","Failed to parse feed http://feeds.dailykos.com/dailykos/index.xml\n","Failed to parse feed http://www.downloadsquad.com/rss.xml\n","Failed to parse feed http://www.gapingvoid.com/index.rdf\n","Failed to parse feed http://www.gawker.com/index.xml\n","Failed to parse feed http://www.huffingtonpost.com/raw_feed_index.rdf\n","Failed to parse feed http://www.hyperorg.com/blogger/index.rdf\n","Failed to parse feed http://www.joystiq.com/rss.xml\n","Failed to parse feed http://littlegreenfootballs.com/weblog/lgf-rss.php\n","Failed to parse feed http://www.makezine.com/blog/index.xml\n","Failed to parse feed http://xml.metafilter.com/rss.xml\n","Failed to parse feed http://www.micropersuasion.com/index.rdf\n","Failed to parse feed http://www.perezhilton.com/index.xml\n","Failed to parse feed http://www.plasticbag.org/index.rdf\n","Failed to parse feed http://www.readwriteweb.com/rss.xml\n","Failed to parse feed http://scienceblogs.com/sample/combined.xml\n","Failed to parse feed http://www.sifry.com/alerts/index.rdf\n","Failed to parse feed http://www.simplebits.com/xml/rss.xml\n","Failed to parse feed http://feeds.feedburner.com/Spikedhumor\n","Failed to parse feed http://www.talkingpointsmemo.com/index.xml\n","Failed to parse feed http://www.thesuperficial.com/index.xml\n","Failed to parse feed http://www.treehugger.com/index.rdf\n","Failed to parse feed http://www.tuaw.com/rss.xml\n","Failed to parse feed http://www.valleywag.com/index.xml\n","Failed to parse feed http://www.we-make-money-not-art.com/index.rdf\n","Failed to parse feed http://www.wonkette.com/index.xml\n","Conpleted. Failed to parse 0.44\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5hWSWMxNqaCP","colab_type":"code","colab":{}},"source":["# Calculate document(blog) frequency\n","word_list = []\n","for w, bc in ap_count.items():\n","  ap_prob = float(bc)/len(feed_list)\n","  if ap_prob > 0.1 and ap_prob < 0.5:\n","    word_list.append(w)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8HOfYAbE5Lqe","colab_type":"code","colab":{}},"source":["# Create word list for each blog\n","with open('blogdata.txt', 'w') as f:\n","  f.write('Blog')\n","  for word in word_list:\n","    f.write('\\t%s' % word)\n","  f.write('\\n')\n","  for blog, wc in word_counts.items():\n","    f.write(blog)\n","    for word in word_list:\n","      if word in wc:\n","        f.write('\\t%s' % wc[word])\n","      else:\n","        f.write('\\t0')\n","    f.write('\\n')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_wWmS2oM7ChO","colab_type":"text"},"source":["# Clusters: Binary"]},{"cell_type":"code","metadata":{"id":"7tvo3G0-5o5u","colab_type":"code","colab":{}},"source":["def readfile(filename):\n","  with open(filename) as f:\n","    lines = f.readlines()\n","  \n","  col_names = lines[0].strip().split('\\t')[1:]\n","  row_names = []\n","  data = []\n","  for line in lines[1:]:\n","    p = line.strip().split('\\t')\n","    row_names.append(p[0])\n","    data.append([float(x) for x in p[1:]])\n","  \n","  return row_names, col_names, data"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3lTYzmDe8Bny","colab_type":"code","colab":{}},"source":["# Define the distance\n","from scipy.spatial.distance import correlation\n","def pearson(x, y):\n","  return correlation(x, y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_xEeh3_M8oui","colab_type":"code","colab":{}},"source":["# Define the binary-cluster\n","class bicluster:\n","  def __init__(self, vec, left=None, right=None, distance=0.0, id=None):\n","    self.left = left\n","    self.right = right\n","    self.vec = vec\n","    self.id = id\n","    self.distance = distance"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ce_AnPqh9-bO","colab_type":"code","colab":{}},"source":["# Clustering: search top-2 most similar classes\n","def hcluster(rows, distance=pearson):\n","  distances = {}\n","  current_clust_id = -1\n","\n","  clust = [bicluster(rows[i], id=i) for i in range(len(rows))]\n","\n","  while len(clust) > 1:\n","    lowest_pair = (0, 1)\n","    closest = distance(clust[0].vec, clust[1].vec)\n","\n","    for i in range(len(clust)):\n","      for j in range(i+1, len(clust)):\n","        if (clust[i].id, clust[j].id) not in distances:\n","          distances[(clust[i].id, clust[j].id)] = distance(clust[i].vec, clust[j].vec)\n","\n","        d = distances[(clust[i].id, clust[j].id)]\n","        #print(d)\n","\n","        if d < closest:\n","          closest = d\n","          lowest_pair = (i, j)\n","    \n","    # Create new cluster by merging 2 clusters from lowest pair\n","    ## calculate average to merge 2 clusters\n","    merge_vec = [(clust[lowest_pair[0]].vec[i] + clust[lowest_pair[1]].vec[i])/2.0 for i in range(len(clust[0].vec))]\n","    ## make new cluster\n","    new_cluster = bicluster(merge_vec, left=clust[lowest_pair[0]], right=clust[lowest_pair[1]], distance=closest, id=current_clust_id)\n","\n","    # id of new clusters is minus value\n","    current_clust_id -= 1\n","    del clust[lowest_pair[1]]\n","    del clust[lowest_pair[0]]\n","    clust.append(new_cluster)\n","\n","  return clust[0]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOMteKbBCel7","colab_type":"code","colab":{}},"source":["# Visualization\n","def print_clust(clust, labels=None, n=0):\n","  for i in range(n):\n","    print(' ',end='')\n","  if clust.id < 0:\n","    print('-')\n","  else:\n","    if labels == None:\n","      print(clust.id)\n","    else:\n","      print(labels[clust.id])\n","  \n","  if clust.left != None:\n","    print_clust(clust.left, labels=labels, n=n+1)\n","  if clust.right != None:\n","    print_clust(clust.right, labels=labels, n=n+1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jz_ng5KuDcdF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b4f5bf82-092b-4460-a878-2f9a1ad7b9be","executionInfo":{"status":"ok","timestamp":1575096899050,"user_tz":-540,"elapsed":1226,"user":{"displayName":"Taichi Aida","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcKjJGJr5u3skF7CZzcu0m1n_npdAFxPcT51W3=s64","userId":"09772046621551990942"}}},"source":["blognames, words, data = readfile('blogdata.txt')\n","clust = hcluster(data)\n","#print(clust)\n","print_clust(clust, labels=blognames)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["-\n"," PaulStamatiou.com - Technology, Design and Photography\n"," -\n","  Autoblog\n","  -\n","   O'Reilly Radar\n","   -\n","    TechEBlog\n","    -\n","     pharyngula\n","     -\n","      -\n","       -\n","        Mashable\n","        -\n","         Engadget RSS Feed\n","         Wired\n","       -\n","        TechCrunch\n","        -\n","         Schneier on Security\n","         -\n","          -\n","           -\n","            The Official Google Blog\n","            -\n","             Google Blogoscoped\n","             -\n","              Google Operating System\n","              Search Engine Roundtable\n","           -\n","            Seth's Blog\n","            -\n","             Lifehack - Feed\n","             ShoeMoney\n","          -\n","           -\n","            TMZ.com\n","            -\n","             Captain's Quarters\n","             -\n","              -\n","               NB Blog Feed\n","               ThinkProgress\n","              -\n","               Latest from Crooks and Liars\n","               -\n","                Boing Boing\n","                -\n","                 Slashdot\n","                 Techdirt.\n","           -\n","            blog maverick\n","            -\n","             Signal v. Noise\n","             -\n","              mezzoblue\n","              -\n","               The Dish\n","               -\n","                Joi Ito's Web\n","                -\n","                 Matt Cutts: Gadgets, Google, and SEO\n","                 -\n","                  Creating Passionate Users\n","                  -\n","                   -\n","                    ongoing by Tim Bray\n","                    -\n","                     Oilman\n","                     -\n","                      Eschaton\n","                      -\n","                       The Viral Garden\n","                       -\n","                        kottke.org\n","                        -\n","                         Derek Powazek\n","                         -\n","                          43 Folders\n","                          -\n","                           WIL WHEATON dot NET\n","                           Neil Gaiman's Journal\n","                   -\n","                    BuzzMachine\n","                    Steve Pavlina\n","      -\n","       -\n","        Guy Kawasaki\n","        -\n","         Copyblogger\n","         ProBlogger\n","       -\n","        Quick Online Tips\n","        -\n","         The Write News\n","         -\n","          Gothamist\n","          -\n","           Joel on Software\n","           -\n","            Deadspin\n","            -\n","             Lifehacker\n","             -\n","              Gizmodo\n","              Kotaku\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qIHSOEELHUJD","colab_type":"text"},"source":["# Clusters: k-means"]},{"cell_type":"code","metadata":{"id":"kgGY_t7oD2h4","colab_type":"code","colab":{}},"source":["import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9I_211O6Hu06","colab_type":"code","colab":{}},"source":["def kcluster(rows, distance=pearson, k=4):\n","  ranges = [(min(row[i] for row in rows), max(row[i] for row in rows)) for i in range(len(rows[0]))]\n","  # randomly setting k-clusters at first. each value is range(min, max)\n","  clusters = [[random.random()*(ranges[i][1]-ranges[i][0])+ranges[i][0] for i in range(len(rows[0]))] for j in range(k)]\n","  \n","  last_matches = None\n","  \n","  for t in range(100):\n","    print('iteration %d' % t)\n","    best_matches = [[] for j in range(k)]\n","\n","    for i in range(len(rows)):\n","      row = rows[i]\n","      best_match = None\n","      for j in range(k):\n","        d = distance(clusters[j], row)\n","        if best_match == None or d < distance(clusters[best_match], row):\n","          best_match = j\n","      best_matches[best_match].append(i)\n","    \n","    # matches time t == matches time t-1 -> end\n","    if best_matches == last_matches:\n","      break\n","    last_matches = best_matches\n","\n","    # reset k-positions\n","    for i in range(k):\n","      avgs = [0.0]*len(rows[0])\n","      if len(best_matches[i]) > 0:\n","        for row_id in best_matches[i]:\n","          for m in range(len(rows[row_id])):\n","            avgs[m] += rows[row_id][m]\n","        for j in range(len(avgs)):\n","          avgs[j] /= len(best_matches[i])\n","      clusters[i] = avgs\n","  \n","  return best_matches\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kmu2eVFeJ4n8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"0bf73a47-f3e0-4fa5-9654-7b7ae9bd14a1","executionInfo":{"status":"ok","timestamp":1575098839394,"user_tz":-540,"elapsed":1920,"user":{"displayName":"Taichi Aida","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcKjJGJr5u3skF7CZzcu0m1n_npdAFxPcT51W3=s64","userId":"09772046621551990942"}}},"source":["blognames, words, data = readfile('blogdata.txt')\n","kclust = kcluster(data, k=10)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["iteration 0\n","iteration 1\n","iteration 2\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n","  dist = 1.0 - uv / np.sqrt(uu * vv)\n"],"name":"stderr"},{"output_type":"stream","text":["iteration 3\n","iteration 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OUXDuFA1M6S9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"outputId":"235e8d97-4930-4ef1-8c73-0ee905f02b56","executionInfo":{"status":"ok","timestamp":1575099035253,"user_tz":-540,"elapsed":1356,"user":{"displayName":"Taichi Aida","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcKjJGJr5u3skF7CZzcu0m1n_npdAFxPcT51W3=s64","userId":"09772046621551990942"}}},"source":["for i in range(10):\n","  print([blognames[r] for r in kclust[i]])"],"execution_count":55,"outputs":[{"output_type":"stream","text":["['The Viral Garden', 'WIL WHEATON dot NET', 'BuzzMachine', 'Matt Cutts: Gadgets, Google, and SEO', 'mezzoblue', \"Neil Gaiman's Journal\", 'Oilman', 'Derek Powazek', 'Steve Pavlina']\n","['PaulStamatiou.com - Technology, Design and Photography', \"Seth's Blog\", 'Lifehack - Feed', 'ShoeMoney']\n","[]\n","['Guy Kawasaki', 'Copyblogger', 'ProBlogger']\n","['Signal v. Noise', 'Eschaton', 'Creating Passionate Users', \"Joi Ito's Web\", 'pharyngula', 'The Dish', '43 Folders', 'blog maverick', 'kottke.org', 'Schneier on Security', 'ongoing by Tim Bray']\n","['Gizmodo', 'Mashable', 'The Write News', 'Deadspin', 'Engadget RSS Feed', 'Gothamist', 'Joel on Software', 'Kotaku', 'Lifehacker', 'Quick Online Tips', 'Wired']\n","['NB Blog Feed', 'ThinkProgress']\n","[\"O'Reilly Radar\", 'Slashdot', 'Autoblog', 'Boing Boing', \"Captain's Quarters\", 'Latest from Crooks and Liars', 'TechCrunch', 'Techdirt.', 'TechEBlog', 'TMZ.com']\n","['Google Blogoscoped', 'Google Operating System', 'Search Engine Roundtable']\n","['The Official Google Blog']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O0szENToO3eE","colab_type":"text"},"source":["# More"]},{"cell_type":"markdown","metadata":{"id":"bzJvBCR0O-h9","colab_type":"text"},"source":["## Distance: Tanimoto/Jaccard\n"," - if the data is binary(0 or 1, exist or none), Tanimoto/Jaccard is useful to calculate a **Duplication rate**"]},{"cell_type":"code","metadata":{"id":"j24kojupMCOZ","colab_type":"code","colab":{}},"source":["def tanimoto(v1, v2):\n","  c1, c2, shr = 0, 0, 0\n","  for i in range(len(v1)):\n","    if v1[i] != 0:\n","      c1 += 1\n","    if v2[i] != 0:\n","      c2 += 1\n","    if v1[i] != 0 and v2[i] != 0:\n","      shr += 1\n","  \n","  return 1.0 - (float(shr)/(c1+c2-shr))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rbYKS5KRUIqi","colab_type":"text"},"source":["## Plot: into 2 dimensions"]},{"cell_type":"code","metadata":{"id":"gVMVVN_LUbR0","colab_type":"code","colab":{}},"source":["import numpy as np\n","from scipy.sparse.linalg import svds\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JM2N-YmwbeS2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"3e887474-8421-4ffc-cdea-e7efb11c99bf","executionInfo":{"status":"ok","timestamp":1575102594009,"user_tz":-540,"elapsed":5842,"user":{"displayName":"Taichi Aida","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAcKjJGJr5u3skF7CZzcu0m1n_npdAFxPcT51W3=s64","userId":"09772046621551990942"}}},"source":["!pip install Pillow"],"execution_count":91,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rHZmxRA5bjDC","colab_type":"code","colab":{}},"source":["from PIL import Image, ImageDraw"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lW44_0b6UFUs","colab":{}},"source":["def data2numpy(data):\n","  return np.array(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iDNx8x14U0jJ","colab_type":"code","colab":{}},"source":["def svd(array, dim=2):\n","  U, S, V = svds(array, k=dim)\n","  S = np.diag(S)\n","  return np.dot(U, S)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ejs-dE2VdiG","colab_type":"code","colab":{}},"source":["def draw2d(data, labels, dim=2):\n","  array = data2numpy(data)\n","  array_2d = svd(array, dim)\n","  \n","  x = [a[0] for a in array_2d]\n","  y = [a[1] for a in array_2d]\n","  \n","  img = Image.new('RGB', (2000, 2000), (255, 255, 255))\n","  draw = ImageDraw.Draw(img)\n","  for i in range(len(labels)):\n","    draw.text((x[i]*10,y[i]*10), labels[i], (0,0,0))\n","  \n","  img.save('blog.jpg', 'JPEG')\n","  \n","  \"\"\"\n","  #plt.scatter(x, y)\n","  for i in range(len(labels)):\n","    plt.text(x[i], y[i], labels[i])\n","  plt.savefig('blog.png')\n","  \"\"\"\n","  return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlOa1xcQWEfD","colab_type":"code","colab":{}},"source":["draw2d(data, blognames, dim=2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6g7rLKUbW5Y8","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}